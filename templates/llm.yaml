apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-service
  template:
    metadata:
      labels:
        app: llm-service
    spec:
      containers:
        - name: llm-service
          image: {{ .Values.llm.image }}
          command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "{{ .Values.llm.port }}"]
          ports:
            - containerPort: {{ .Values.llm.port }}
          env:
            - name: RABBITMQ_HOST
              value: {{ .Values.global.env.RABBIT_HOST | quote }}
            - name: RABBITMQ_PORT
              value: {{ .Values.global.env.RABBIT_PORT | quote }}
            - name: RABBITMQ_USER
              value: {{ .Values.global.env.RABBIT_USER | quote }}
            - name: RABBITMQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ .Release.Name }}-secrets
                  key: rabbitmq-password
            - name: REDIS_HOST
              value: {{ .Values.global.env.REDIS_HOST | quote }}
            - name: REDIS_PORT
              value: {{ .Values.global.env.REDIS_PORT | quote }}
            - name: GEMINI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Release.Name }}-secrets
                  key: gemini-api-key
            - name: PROXY_URL
              valueFrom:
                secretKeyRef:
                  name: {{ .Release.Name }}-secrets
                  key: proxy-url
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "300m"
              memory: "512Mi" 
---
apiVersion: v1
kind: Service
metadata:
  name: llm-service
spec:
  ports:
    - port: {{ .Values.llm.port }}
  selector:
    app: llm-service