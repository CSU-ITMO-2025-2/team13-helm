apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-service
  template:
    metadata:
      labels:
        app: llm-service
    spec:
      containers:
        - name: llm-service
          image: "{{ .Values.llm.image.repository }}:{{ .Values.llm.image.tag }}"
          imagePullPolicy: {{ .Values.llm.image.pullPolicy }}
          command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "{{ .Values.llm.port }}"]
          ports:
            - containerPort: {{ .Values.llm.port }}
          envFrom:
            - configMapRef:
                name: llm-service-config
          env:
            - name: RABBITMQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: RABBITMQ_PASSWORD
                  name: team13-config
            - name: GEMINI_API_KEY
              valueFrom:
                secretKeyRef:
                  key: GEMINI_API_KEY
                  name: team13-config
            - name: PROXY_URL
              valueFrom:
                secretKeyRef:
                  key: PROXY_URL
                  name: team13-config
          resources:
            requests:
              cpu: "100m"
              memory: "128Mi"
            limits:
              cpu: "300m"
              memory: "512Mi" 
---
apiVersion: v1
kind: Service
metadata:
  name: llm-service
spec:
  ports:
    - port: {{ .Values.llm.port }}
  selector:
    app: llm-service